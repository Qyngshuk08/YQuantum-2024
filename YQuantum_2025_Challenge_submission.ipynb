{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**YQuantum 2025 Challenge : Team Polytrit Panacea**"
      ],
      "metadata": {
        "id": "tD4yoXuXPuBf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quantum Hash Function\n"
      ],
      "metadata": {
        "id": "1ogH16puPVd-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qiskit"
      ],
      "metadata": {
        "id": "yAzgZZkkPsUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Define the Hash Function Circuit"
      ],
      "metadata": {
        "id": "fymSt_V6aOfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from qiskit import QuantumCircuit, Aer, execute\n",
        "from qiskit.visualization import plot_histogram\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from itertools import product\n",
        "\n",
        "def input_to_angles(bitstring):\n",
        "    return [np.pi if b == '1' else 0 for b in bitstring]\n",
        "\n",
        "def quantum_hash_function(input_bits):\n",
        "    angles = input_to_angles(input_bits)\n",
        "    qc = QuantumCircuit(4, 4)\n",
        "\n",
        "    for i in range(4):\n",
        "        qc.ry(angles[i], i)\n",
        "\n",
        "    qc.cx(0, 1)\n",
        "    qc.cx(1, 2)\n",
        "    qc.cx(2, 3)\n",
        "\n",
        "    qc.h(0)\n",
        "    qc.rz(np.pi/4, 1)\n",
        "    qc.rx(np.pi/3, 2)\n",
        "    qc.ry(np.pi/5, 3)\n",
        "    qc.cz(0, 3)\n",
        "\n",
        "    qc.measure(range(4), range(4))\n",
        "\n",
        "    backend = Aer.get_backend('qasm_simulator')\n",
        "    job = execute(qc, backend, shots=1024)\n",
        "    result = job.result()\n",
        "    counts = result.get_counts()\n",
        "\n",
        "    return counts\n",
        "\n",
        "# Generate all 4-bit binary strings\n",
        "all_inputs = [''.join(bits) for bits in product('01', repeat=4)]\n",
        "\n",
        "# Run the hash function on all inputs and store results\n",
        "all_counts = {inp: quantum_hash_function(inp) for inp in all_inputs}\n",
        "\n",
        "# Plotting\n",
        "fig, axs = plt.subplots(4, 4, figsize=(18, 14))\n",
        "fig.suptitle('Quantum Hash Outputs for All 4-bit Inputs', fontsize=20)\n",
        "\n",
        "for idx, inp in enumerate(all_inputs):\n",
        "    row, col = divmod(idx, 4)\n",
        "    ax = axs[row, col]\n",
        "    plot_histogram(all_counts[inp], ax=ax, title=f\"Input: {inp}\", bar_labels=False)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust(top=0.92)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PRvob3HmaM8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Preimage & Collision Resistance Analysis"
      ],
      "metadata": {
        "id": "OfQ5ufpYaY0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.spatial.distance import cosine\n",
        "from itertools import combinations\n",
        "\n",
        "# Convert counts to probability vectors over all possible 4-bit outputs\n",
        "def counts_to_prob_vector(counts, shots=1024):\n",
        "    all_outputs = [format(i, '04b') for i in range(16)]\n",
        "    return np.array([counts.get(k, 0) / shots for k in all_outputs])\n",
        "\n",
        "# Compute cosine similarities between every pair of hash outputs\n",
        "similarity_matrix = []\n",
        "collisions = []\n",
        "\n",
        "inputs = list(all_counts.keys())\n",
        "prob_vectors = {inp: counts_to_prob_vector(all_counts[inp]) for inp in inputs}\n",
        "\n",
        "for a, b in combinations(inputs, 2):\n",
        "    sim = 1 - cosine(prob_vectors[a], prob_vectors[b])\n",
        "    similarity_matrix.append((a, b, sim))\n",
        "    if sim > 0.95:  # high similarity = potential collision\n",
        "        collisions.append((a, b, sim))\n",
        "\n",
        "# Show potential collisions\n",
        "print(\"🔁 Potential Collisions (Cosine Similarity > 0.95):\")\n",
        "for a, b, sim in collisions:\n",
        "    print(f\"Inputs {a} and {b} -> Similarity: {sim:.4f}\")\n",
        "\n",
        "# Show average similarity (lower is better)\n",
        "avg_sim = np.mean([sim for _, _, sim in similarity_matrix])\n",
        "print(f\"\\n📉 Average Pairwise Cosine Similarity: {avg_sim:.4f}\")\n"
      ],
      "metadata": {
        "id": "X1oQx6Juafay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Entropy & Randomness of Hash Output"
      ],
      "metadata": {
        "id": "KTevvwwRampH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import entropy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "entropy_values = {}\n",
        "\n",
        "for inp, probs in prob_vectors.items():\n",
        "    ent = entropy(probs, base=2)  # log base 2 = bits\n",
        "    entropy_values[inp] = ent\n",
        "\n",
        "# Print entropy values\n",
        "print(\"🧮 Entropy of each input's hash output:\")\n",
        "for inp, ent in entropy_values.items():\n",
        "    print(f\"Input {inp}: Entropy = {ent:.4f} bits\")\n",
        "\n",
        "# Plotting entropy\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(entropy_values.keys(), entropy_values.values(), color='skyblue')\n",
        "plt.ylim(0, 4)  # max for 4-bit output\n",
        "plt.xlabel(\"Input Bitstring\")\n",
        "plt.ylabel(\"Shannon Entropy (bits)\")\n",
        "plt.title(\"Entropy of Quantum Hash Outputs\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Summary\n",
        "avg_entropy = np.mean(list(entropy_values.values()))\n",
        "print(f\"\\n📊 Average Entropy Across All Inputs: {avg_entropy:.4f} bits\")\n"
      ],
      "metadata": {
        "id": "2iTzZ1H7asJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Scalability and Circuit Optimization"
      ],
      "metadata": {
        "id": "PBFf6y62a4EN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling to N qubits and running entropy analysis for larger inputs\n",
        "def simulate_hash_with_qubits(n_qubits):\n",
        "    \"\"\" Simulate the hash function for varying numbers of qubits. \"\"\"\n",
        "    inputs = [bytes(np.random.randint(0, 256, n_qubits)) for _ in range(100)]\n",
        "    prob_vectors = {}\n",
        "\n",
        "    for inp in inputs:\n",
        "        hash_output = simple_quantum_hash(inp)\n",
        "        prob_vectors[inp] = calc_probability_distribution(hash_output)\n",
        "\n",
        "    # Calculate entropy for each hash output\n",
        "    entropy_values = {inp: entropy(probs, base=2) for inp, probs in prob_vectors.items()}\n",
        "    return entropy_values\n",
        "\n",
        "# Test with 10 qubits, 15 qubits, and 20 qubits\n",
        "qubit_tests = [10, 15, 20]\n",
        "all_entropy = {}\n",
        "\n",
        "for qubits in qubit_tests:\n",
        "    entropy_values = simulate_hash_with_qubits(qubits)\n",
        "    avg_entropy = np.mean(list(entropy_values.values()))\n",
        "    all_entropy[qubits] = avg_entropy\n",
        "\n",
        "# Plot the entropy comparison for different qubit numbers\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(all_entropy.keys(), all_entropy.values(), marker='o', color='green')\n",
        "plt.xlabel(\"Number of Qubits\")\n",
        "plt.ylabel(\"Average Entropy (bits)\")\n",
        "plt.title(\"Entropy vs Number of Qubits\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Print Entropy comparison\n",
        "for qubits, entropy_val in all_entropy.items():\n",
        "    print(f\"With {qubits} qubits, the average entropy is {entropy_val:.4f} bits\")\n"
      ],
      "metadata": {
        "id": "n4ScJetDa74I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Final Testing and Profiling"
      ],
      "metadata": {
        "id": "mqg__ByvbRjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Test the hash function for 10 qubits and measure time\n",
        "start_time = time.time()\n",
        "simulate_hash_with_qubits(10)\n",
        "end_time = time.time()\n",
        "print(f\"Execution time for 10 qubits: {end_time - start_time:.5f} seconds\")\n"
      ],
      "metadata": {
        "id": "hLRfMfnUb2Xq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
